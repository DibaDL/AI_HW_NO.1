{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724bf4c2",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Chapter 1 & 2\n",
    "## Student Name: Diba Elahi\n",
    "## Student ID : 400222007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3b0af",
   "metadata": {},
   "source": [
    "### Question no. 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871622f2",
   "metadata": {},
   "source": [
    "#### Intelligence\n",
    "Intelligence is the ability to act depending on your goal, and try to do it with utility and also being able to understand and have percepts about your environment. \n",
    "#### Artificial Intelligence\n",
    "Kind of computer system that is able to perform tasks as if it has human intelligence and in a way that there won't be a clear difference between tow same tasks that one had been performed by AI and one else by a human. And human intelligence cannot differ this 2 tasks and understand which one has been done by AI and which one by a human. \n",
    "#### Agent\n",
    "Sth that performs an action, it operate autonomously, pereceive its environmnet, adapt to change and craete and pursue goals. \n",
    "#### Rationality\n",
    "Doing the right thing based on the situation we are in and a rational agent is the agent that tries to do the right thing by maximaizing its performance. In other words we can say a rational agent acts to achieve the best outcome or at least try for it and do its best. \n",
    "#### Logical Reasoning\n",
    "Using logic to decide what to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a31a9",
   "metadata": {},
   "source": [
    "### Question no. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ece02",
   "metadata": {},
   "source": [
    "The Loebner Prize award had retired after 2020. So the last year that this award had been held was 2019. \n",
    "Last winner was Mitsuku Chatbot by Steve Worswick. Mitsuku is a 4 times(2016-2019) winner of the Loebner Prize and regarded as the world's most humanlike conversational AI. This AI is an hand-coded open domain chatbot which is not using machine learning. The AI with the best scores are based on deep learning and often transformer architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4442278d",
   "metadata": {},
   "source": [
    "### Question no. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fb327",
   "metadata": {},
   "source": [
    "Those actions are encoded in our DNA and help us survive. It is like giving some rules to an agent before it starts learning. \n",
    "I think that these reflexive actions are not based on our intelligence. A reflex seems more like an involuntary action that we haven't thought about it. Reflexive actions are done without the intelligent mind thinking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053273d2",
   "metadata": {},
   "source": [
    "### Question no. 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52585f04",
   "metadata": {},
   "source": [
    "#### Supermarket bar code scanners:\n",
    "Supermarket barcode scanners do not include artificial intelligence because there is no autonomous activity in scanning barcodes. Barcode scanners used in supermarkets are mostly laser or image-based scanners that only have to read the barcode correctly. They don't need intelligence and don't seem that they are using intelligence to perform an action or have any perception about the environment. \n",
    "#### Web search engines:\n",
    "Search engines rely on artificial intelligence (AI) to function. Big search engines like Google rely on sophisticated AI to determine how content gets ranked. The algorithms used by these AI systems have many rules that prioritize different factors, from the types of keywords in your content to your site's user experience.\n",
    "#### Voice-activated telephone menus:\n",
    "It needs to recognize any kind of voice, which is a difficult problem. They just disply and don't perform any action, but they should have intelligence to understand the meaning of the voice they got as an input so I think they have artificial intelligence to recognize the voice. \n",
    "#### Internet routing algorithms that respond dynamically to the state of the network:\n",
    "It is a instance of AI as it has make decisions based on the state of network.\n",
    "#### Spelling and grammar correction features in Microsoft Word:\n",
    "It is a instance of AI as it is constantly evaluating the grammar and spelling of sentence and provides the appropriate corrections. Also needs natural language processing which is part of AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c943f",
   "metadata": {},
   "source": [
    "### Question no. 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85a8cb",
   "metadata": {},
   "source": [
    "We don't know how it works because it is part of unconsciousness and we haven't thought about it. Computer vision  works completely differently than human vision. It relies on the computer’s neural network that allows the computer to perform some steps. Like receive an image, detect the image’s pixels, detect its edges and contours, make a guess about what the image is. Human vision depends on each person’s visual cortex. Computers can’t see in the way that we humans can. More importantly, computers don’t have the consciousness and required to form conceptions and contexts about what they see in the way that we humans can. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c3c43",
   "metadata": {},
   "source": [
    "### Question no. 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7989b3",
   "metadata": {},
   "source": [
    "I think these skills are required to operate, and also I think as we can expand our abilities by focusing on the basics but they might look useless but I think that by playing or doing simple logical reasoning we can imporove our cognitive abilities. So as we try to focus on more advance abilities we should focus on simple logical activities that expand our abilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f4ba6",
   "metadata": {},
   "source": [
    "### Qiestion no. 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2efab",
   "metadata": {},
   "source": [
    "Yes, but it doesn't imply it. It just needs to be programmed in a flexible way that allows internal decisions to alter internal functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581e2bd",
   "metadata": {},
   "source": [
    "### Question no. 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f663e",
   "metadata": {},
   "source": [
    "Animals, like humans, learn while they live. And they have perceptions about their world and also they can learn for example one time they see an animal causing problem for them, they will be scared of them. This reaction could save their life. This is an example of adaptation. So I think they are not in the same level of intelligence as human are but they have kind of intelligence that they need in their own world. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce59d84",
   "metadata": {},
   "source": [
    "### Question no. 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cfa19e",
   "metadata": {},
   "source": [
    "No, if this were true then humans would have never invented any thing new. With physics law only, we counldn't have done anything. So human had used their intelligence and combined it with physics law and tried to invent new things. I personally think having some rules doesn't mean that we are out of intelligence and we just copy everything based on rules. Having intelligence and mixing it with rules that are basis can help us be able to invent new things and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc1056",
   "metadata": {},
   "source": [
    "### Question no. 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b382d",
   "metadata": {},
   "source": [
    "#### An agent that senses only partial information about the state cannot be perfectly rational.\n",
    "It is FALSE. There are a lot of agents that their environment observability is partial. For example in taxi driving task environment. As we had this example in text book too, the environment of a taxi driver or a poker player is not fully observable byt they also are agents that are acting. \n",
    "#### There exist task environments in which no reflex agent can behave rationally. \n",
    "It is TRUE. A reflex agent ignores previous percepts and cannot obtain an optimal state estimate in a partially\n",
    "observable environment. And in this situation having no information about former percepts might make it very hard and in some cases it might cause problems that our pure reflexive agent cannot perform. \n",
    "#### There exists a task environment in which every agent is rational.\n",
    "It is TRUE. For example, in an environment with a single state, such that all actions have the same reward, it does not matter which action is taken. \n",
    "#### The input to an agent program is the same as the input to the agent function.\n",
    "It is FALSE. The agent function, takes asinput the entire percept up to that point, while the agent\n",
    "program takes the current percept only. \n",
    "####  Every agent function is implementable by some program/machine combination. \n",
    "It is TRUE. \n",
    "####  Suppose an agent selects its action uniformly at random from the set of possible actions. There exists a deterministic task environment in which this agent is rational\n",
    "It is TRUE. \n",
    "#### It is possible for a given agent to be perfectly rational in two distinct task environments. \n",
    "When I think about it it looks very rare that an agent can perform rationally in 2 distinct environment. Because our agent no matter what kind of agents it is has some action sets depends on its percepts of the environment and it is a little hard to sync 2 distinct environment in a way that they percepts and actions match so I think it is FALSE. \n",
    "#### Every agent is rational in an unobservable environment\n",
    "?\n",
    "#### A perfectly rational poker-playing agent never loses.\n",
    "It is FALSE. Unless it draws the perfect hand, the agent can lose\n",
    "if an opponent has better cards so it is not all about intelligence, chance should be also considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf538f",
   "metadata": {},
   "source": [
    "### Question no. 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ab763",
   "metadata": {},
   "source": [
    "####  Soccer Player Robot\n",
    "Performance :  number of your own team faults, number of your enemy team\n",
    "faults, number of your own team goals, number of your enemy team goals.\n",
    "\n",
    "Environment :  soccer field, all players, enemy players, referee, bystanders. \n",
    "\n",
    "Actuators : agent's body to perfom actions. \n",
    "\n",
    "Sensors : visual sensors, speedometer\n",
    "\n",
    "#### Shopping books on the Internet.\n",
    "Performance : max books quality, min price\n",
    "\n",
    "Environment : internet, online book selling websites\n",
    "\n",
    "Actuators : ability to buy books\n",
    "\n",
    "Sensors : website's content\n",
    "\n",
    "#### Autonomous agents to walk on Mars\n",
    "Performance : if it walks on all points of Mars.\n",
    "\n",
    "Environment : Mars surface\n",
    "\n",
    "Actuators : agent that perform walking by moving its position\n",
    "\n",
    "Sensors : visual sensors, heat sensor. \n",
    "\n",
    "#### An agent helps to imply mathematics theorem\n",
    "Performance : how valid its implies are\n",
    "\n",
    "Environment : mathematical rules and restrictions\n",
    "\n",
    "Actuators : agent that performs the imply steps\n",
    "\n",
    "Sensors : percept the condition of the theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b220f5c",
   "metadata": {},
   "source": [
    "### Question no. 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7fcb1",
   "metadata": {},
   "source": [
    "#### Agent\n",
    "Sth that acts and for its actions, it operate autonomously, pereceive its environmnet, adapt to change and craete and pursue goals. \n",
    "#### Agent Function\n",
    "Agent function is what maps any given percept sequence to an action. \n",
    "#### Agent Program\n",
    "Agent program is what implement the agent function for an artificial intelligence. \n",
    "#### Rationality\n",
    "Doing the right thing based on the situation we are in and a rational agent is the agent that tries to do the right thing by maximaizing its performance. In other words we can can say a rational agent acts to achieve the best outcome or in the case of uncertainty, to achieve the best expected outcome. \n",
    "#### Autonomy\n",
    "Learning what it can (as an agent) to compensate for partial or incorrect prior knowledge. \n",
    "#### Reflexive Agent\n",
    "Kind of agents that select actions on the basis of the current percepts, ignoring the rest of the percept history. \n",
    "#### Model-based Agent\n",
    "It is kind of agents that can work in a partially observable environment and track the situation. It has 2 important factors: Modek and Internal State. Model is the knowledge of the world. It also needs 2 information in order to update state: 1.How the world evolves and 2.How the agent's action affects the wirld. \n",
    "#### Goal-based Agent\n",
    "Goal-based agents are agents that expand the capabilities of the model-based agrnt by having some information about its goal. And it is obvious that this kind of agents choose an action that helps achieve the goal. These agents may have to consider a long sequence of possible actions before deciding whether the goal is achieved or not. \n",
    "#### Utility-based Agent\n",
    "These agents are similar to the goal-based agent but provide an extra component of utility measurement which makes them different by providing a measure of success at a given state. They not only consider achieving goal but also achieving it in the best way possible(utilized). The utility function maps each state to a real number to check how efficiently each action achieves the goals\n",
    "\n",
    "#### Learning Agent\n",
    "A learning agent in AI is the type of agent which can learn from its past experiences, or it has learning capabilities.It starts to act with basic knowledge and then able to act and adapt automatically through learning.\n",
    "A learning agent has mainly four conceptual components, which are: Learning element, critic, performance element and, problem generator. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ecbac3",
   "metadata": {},
   "source": [
    "### Question no. 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67efa0f6",
   "metadata": {},
   "source": [
    "#### Can there be more than one agent program that implements a given agent function? Give an example, or show why one is not possible\n",
    "It is TRUE. Vacuum can clean depending vision sensors, but also with other sensors, for example have a dirt sensor. \n",
    "####  Are there agent functions that cannot be implemented by any agent program?\n",
    "Yes. \n",
    "#### Given a fixed machine architecture, does each agent program implement exactly one agent function?\n",
    "No. \n",
    "#### Given an architecture with n bits of storage, how many different possible agent programs are there? \n",
    "$$ 2^n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b7801",
   "metadata": {},
   "source": [
    "### Question no. 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88570fa",
   "metadata": {},
   "source": [
    "#### Goal-based Agent\n",
    "\n",
    "*************************************\n",
    "function GOAL-BASED-AGENT(percept) returns an action    \n",
    "\n",
    "  persistent: state, the agent’s current perception of the world state it is on right now\n",
    "  goal, a description of what the agent would like to achieve        \n",
    "  rules, a set of condition and action rules\n",
    "  action, the most recent action, initial action(we can initialize sth for the first action for the firs iterate)\n",
    "  \n",
    "  state  : UPDATE-STATE (state, action, percept, goal)\n",
    "\n",
    "  rule   :  RULE (state, rules, goal)\n",
    "\n",
    "action ← rule.ACTION\n",
    "\n",
    "return action\n",
    "***************************************\n",
    "#### Utility-based Agent\n",
    "\n",
    "***************************************\n",
    "function UTILITY-BASED-AGENT(percept) returns an action\n",
    "\n",
    "  persistent: state, the agent’s current conception of the world state it is on right now\n",
    "  possible states, possible states that may maximize happiness\n",
    "  rules, a set of condition and action rules\n",
    "  action, the most recent action, initial action(we can initialize sth for the first action for the firs iterate)\n",
    "  \n",
    "  state : UPDATE-STATE (state, action, percept, possible states)\n",
    "  \n",
    "  rule  : RULE (state, rules, possible states)\n",
    "  \n",
    "  action ← rule.ACTION\n",
    "  \n",
    "  return action\n",
    "****************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e130d",
   "metadata": {},
   "source": [
    "### First Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2904d",
   "metadata": {},
   "source": [
    "I think 3 is the correct answer. When we have confilicting goals it is obvious that we cannot reach our goals just by a simple goal-based model. But when we mix it with utility-based architecture, in each step we will think that by performing an action how happy we will be and this helps to achieve goals that are utilized. So when we see that we cannot achieve all of our goals because they are confilicting at least we can try to persue the utilized goals and it is a better choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa10d1",
   "metadata": {},
   "source": [
    "### Second Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6d3d1",
   "metadata": {},
   "source": [
    "I think 4 is the correct answer. \n",
    "Because internal state uses the perceptual history to represent a current percept and our agent keeps tarck history of its environment and when it is fully observable I think there is no need to do that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
